{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BART_approach_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1s3WPHPpG3fkZjvNhEYTdvgBbwhVPTgp8?authuser=1#scrollTo=ILb1FeTDcnmC)"
      ],
      "metadata": {
        "id": "ILb1FeTDcnmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-tune BART for the arguemnt-keypoint matching pipeline\n",
        "#### Input: Arguments\n",
        "#### Output: Intermediary text"
      ],
      "metadata": {
        "id": "rqZ2bZBjpXDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the simple transformers, tqdm, pandas packages"
      ],
      "metadata": {
        "id": "fz7xRNupqR5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers tqdm pandas"
      ],
      "metadata": {
        "id": "D8sEfr_GcwQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the train, dev and test sets"
      ],
      "metadata": {
        "id": "tVXV9czfqzIE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lblpc03QcOwH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df_prev = pd.read_csv(\"train.csv\")\n",
        "dev_df_prev = pd.read_csv(\"dev.csv\")\n",
        "test_df_prev = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_prev.head(5)"
      ],
      "metadata": {
        "id": "A9HjCGIDcmqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_prev.columns"
      ],
      "metadata": {
        "id": "kZlKnC66ecGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only need the 'argument', 'keypoint' and 'label' columns"
      ],
      "metadata": {
        "id": "-bEZ7wg9q-IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df_prev.filter(['argument', 'key_point', 'label'], axis=1)\n",
        "dev_df = dev_df_prev.filter(['argument', 'key_point', 'label'], axis=1)\n",
        "test_df = test_df_prev.filter(['argument', 'key_point', 'label'], axis=1)"
      ],
      "metadata": {
        "id": "6_UWAy0qecQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(5)"
      ],
      "metadata": {
        "id": "gAzLtIHZecX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two prompt engineering templates for the task.\n",
        "Template 1: [X]. This means [Z].\n",
        "Template 2: What are the keypoints for the following argument? [X] [Z]\n",
        "where, X is the argument as input and Z is the intermediary text as output.\n",
        "\n",
        "You need to select either template 1 or template 2 for fine-tuning BART"
      ],
      "metadata": {
        "id": "Ija6SXkprca4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is template 1"
      ],
      "metadata": {
        "id": "sbDwpqqvtLvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Template 1\n",
        "# For Train set\n",
        "\n",
        "for i in train_df.index:\n",
        "  arg = train_df['argument'][i]\n",
        "  if arg[-1] != '.':\n",
        "    modified_arg = arg + '. This means '\n",
        "    train_df.at[i, 'argument'] = modified_arg\n",
        "  else:\n",
        "    modified_arg = arg + ' This means '\n",
        "    train_df.at[i, 'argument'] = modified_arg\n",
        "\n",
        "# For Dev set\n",
        "\n",
        "for i in dev_df.index:\n",
        "  arg = dev_df['argument'][i]\n",
        "  if arg[-1] != '.':\n",
        "    modified_arg = arg + '. This means '\n",
        "    dev_df.at[i, 'argument'] = modified_arg\n",
        "  else:\n",
        "    modified_arg = arg + ' This means '\n",
        "    dev_df.at[i, 'argument'] = modified_arg"
      ],
      "metadata": {
        "id": "bDQw27AEecgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is Template 2"
      ],
      "metadata": {
        "id": "zUtHldAds8C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Template 2\n",
        "# For Train set\n",
        "\n",
        "for i in train_df.index:\n",
        "  arg = train_df['argument'][i]\n",
        "  if arg[-1] != '.':\n",
        "    modified_arg = 'What are the keypoints for the following argument? ' + arg + '.'\n",
        "    train_df.at[i, 'argument'] = modified_arg\n",
        "  else:\n",
        "    modified_arg = 'What are the keypoints for the following argument? ' + arg\n",
        "    train_df.at[i, 'argument'] = modified_arg\n",
        "\n",
        "# For Dev set\n",
        "\n",
        "for i in dev_df.index:\n",
        "  arg = dev_df['argument'][i]\n",
        "  if arg[-1] != '.':\n",
        "    modified_arg = 'What are the keypoints for the following argument? ' + arg + '.'\n",
        "    dev_df.at[i, 'argument'] = modified_arg\n",
        "  else:\n",
        "    modified_arg = 'What are the keypoints for the following argument? ' + arg\n",
        "    dev_df.at[i, 'argument'] = modified_arg"
      ],
      "metadata": {
        "id": "9Nt-TR4fkEIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check a sample whether or not everything is okay."
      ],
      "metadata": {
        "id": "hfk0WGn-tVD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.at[110, 'argument']"
      ],
      "metadata": {
        "id": "le4pbMixkHp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename the columns for compatibility with Simple Transformers"
      ],
      "metadata": {
        "id": "xPoENVMMte8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the columns\n",
        "train_df.columns = [\"input_text\",\"target_text\"]\n",
        "dev_df.columns = [\"input_text\",\"target_text\"]"
      ],
      "metadata": {
        "id": "Qyw6uZMNkKuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, dev_data = train_df, dev_df"
      ],
      "metadata": {
        "id": "56Le3xkVkQuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing is complete. Let's fine-tune BART now!"
      ],
      "metadata": {
        "id": "2WjcGCrFuR7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "import pandas as pd\n",
        "from simpletransformers.seq2seq import (\n",
        "    Seq2SeqModel,\n",
        "    Seq2SeqArgs,\n",
        ")\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "metadata": {
        "id": "zHYE-Ew_nFk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using BART-large here. You can use BART-base as well."
      ],
      "metadata": {
        "id": "uyLhd6CIuduE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args = Seq2SeqArgs()\n",
        "model_args.num_train_epochs = 10\n",
        "model_args.no_save = True\n",
        "model_args.evaluate_generated_text = True\n",
        "model_args.evaluate_during_training = True\n",
        "model_args.evaluate_during_training_verbose = True\n",
        "\n",
        "# Initialize model\n",
        "model = Seq2SeqModel(\n",
        "    encoder_decoder_type=\"bart\",\n",
        "    encoder_decoder_name=\"facebook/bart-large\",\n",
        "    args=model_args,\n",
        "    use_cuda=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "XDomfr_AnHuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_matches(labels, preds):\n",
        "    print(labels)\n",
        "    print(preds)\n",
        "    return sum(\n",
        "        [\n",
        "            1 if label == pred else 0\n",
        "            for label, pred in zip(labels, preds)\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "NxwdzqhjnH3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training starts from here."
      ],
      "metadata": {
        "id": "ChDKOiZcuoM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.train_model(\n",
        "    train_df, eval_data=dev_df, matches=count_matches\n",
        ")\n"
      ],
      "metadata": {
        "id": "QVe0ct09pIyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don''t forget to zip the model files and then upload it to your Google Drive"
      ],
      "metadata": {
        "id": "f7R8qdeYu6eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/t5_base_no_prompt.zip /content/outputs"
      ],
      "metadata": {
        "id": "kMYb1zhzpHQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "673lS_yyoRZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model now. You can pass an input to the model manually and observe the output. Or you can pass an entire test set and get the list of outputs."
      ],
      "metadata": {
        "id": "TqpWrhxEvLOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# results = model.eval_model(dev_df)\n",
        "\n",
        "# Use the model for prediction\n",
        "print(\n",
        "    model.predict(\n",
        "        [\n",
        "            \"What are the key points for the following argument?  marriage provides stability and a commitment between people which strengthens relationships and to abandon it would be to turn out backs on something good.\"\n",
        "        ]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "Fp2K2rWEnH_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict full test set\n",
        "\n",
        "prefix = \"text-classification\"\n",
        "ref = []\n",
        "to_predict = []\n",
        "for i in test_df.index:\n",
        "  input = prefix + \": \" + test_df['input_text'][i]\n",
        "  ref.append(test_df['target_text'][i])\n",
        "  to_predict.append(input)\n",
        "  #pred.append(trained_model.predict(f\"{prefix}: {input}\"))\n",
        "\n",
        "predictions = trained_model.predict(to_predict)"
      ],
      "metadata": {
        "id": "NVdaKA9BnqY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, look at the accuracy, f1-score, precision and recall"
      ],
      "metadata": {
        "id": "TCOHjhmPvhzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(ref, predictions))"
      ],
      "metadata": {
        "id": "xGNxP0OioFEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
